# Leveraging Active Learning for Ocean Data Quality Assessment: Reducing Labeling Workload and Addressing Severe Data Imbalance Challenges
Oceanic research initiatives like Argo, GLOSS, and EMSO aim to enhance our understanding of the oceans and climate through extensive data collection. Maintaining the quality of collected data is essential for effective data analysis and real-world applications. While automated and semi-automated tests can provide real-time or near-real-time validation, thorough quality control still depends on operator review. Consequently, current Quality Control (QC) processes continue to be labor-intensive. Machine Learning (ML) methods, which can analyze vast amounts of data and learn complex patterns autonomously, offer significant potential for improving QC processes. However, challenges like severe data disproportion persist for ML approaches. This article proposes exploiting Active Learning (AL) to assist QC experts, reducing their workload by proactively selecting informative data points for labeling. Targeting the data distribution challenge, AL, coupled with imbalance-resilient classifiers, enhances model performance in recognizing erroneous data points. To mitigate the cold-start problem in AL, we propose outlier detection for initializing classifiers, significantly reducing annotation costs. Our approach is tested on data generated by 5 Argo floats, demonstrating its feasibility to lessen the labeling workload for experts and tackle significant data imbalance. Although the experiments are limited in scale, the findings indicate a promising outlook for using active learning in ocean data quality assessment, facilitating an effective semi-automated quality control framework. 

## Dataset
We use data from five floats provided by Euro Argo. The comprehensive data can be obtained through the data portal https://dataselection.euro-argo.eu/ 

Preprocessed data can be found at 


## Folder explanation
- `preprocessing` module: preprocess argo data, split training and test subsets. The execution order is as follows: 
    1. `argo_preprocessing.ipynb`: Drop NAN, normalization, etc. 
    1.  `random_train_test_split.ipynb`: Split train, val and test subsets
    1. `initial_unlabeled_split.ipynb`: Split initial and unlabeled subsets
    1. `unsupervised_split`: Split initial and unlabeled subsets using outlier detectors
- `classification` module: offline classification without AL
    1. `supervised.ipynb`: Supervised classification methods with all training data as well as with varying sampling ratio
    1. `unsupervised.ipynb`: Unsupervised classification methods
    1. `nn.ipynb`: Neural networks
    1. `plot_classifier_performance.ipynb`: Plot classification performances under varying sampling ratio 
- `active_learning` module: AL
    1. `us.ipynb`: AL using random and uncertainty-based sampling strategies
    1. `qbc.ipynb`: AL using QBC sampling strategy
    1. `plot_us.ioynb`: Plot the results from US method
    1. `plot_qbc.ipynb`: Plot the results from QBC method
    1. `plot_initial_set_size.ipynb`: Plot performances over initial set size
- `visualization` module: Visualize argo data
    1. `eda.ipynb`: General data exploration and visualization for Argo data
    1. `tragectory.ipynb`: Plot the tragectories of the five floats
    1. `tsne_visualization.ipynb`: Visualize the selected samples during AL processes usigng t-SNE method
- `data` store: All the data used for experiments 
- `results` store: Experimental results



## Environment setup
Refer to `env_setup.sh` \
Under Conda `al_dqc` virtual environment. 


## Cite
```
Na Li, Yiyang Qi, Ruyue Xin, Peide Zhu, and Zhiming Zhao. "Leveraging Active Learning for Ocean Data Quality Assessment: Reducing Labeling Workload and Addressing Severe Data Imbalance Challenges." International Journal of Data Science and Analytics (2025).
```
