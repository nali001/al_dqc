{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning methods for classification\n",
    "Methods: \n",
    "- LOF\n",
    "- OCSVM\n",
    "- iForest\n",
    "- DEBSCAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_type = 'random'\n",
    "\n",
    "TRAIN_DIR = f'../data/{split_type}split/train/'\n",
    "TEST_DIR = f'../data/{split_type}split/test/'\n",
    "\n",
    "\n",
    "float_numbers = [\n",
    "    '4903052',\n",
    "    '4903054',\n",
    "    '4903058',\n",
    "    '4903215',\n",
    "    '4903217',\n",
    "    '4903218',\n",
    "    '4903220'\n",
    "]\n",
    "\n",
    "# float_number = '4903217' # high\n",
    "float_number = '4903218' # low1\n",
    "# float_number = '4903220' # low2\n",
    "# float_number = '4903052' # low3\n",
    "# float_number = '4903054' # low4\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_FILE = os.path.join(TRAIN_DIR, f'PR_PF_{float_number}.csv')\n",
    "TEST_FILE = os.path.join(TEST_DIR, f'PR_PF_{float_number}.csv')\n",
    "\n",
    "RESULT_DIR = f'../results/{split_type}split/{float_number}'\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_ratio(dataset):\n",
    "    ''' Compute anomaly ratio\n",
    "    '''\n",
    "    instance = dataset[(dataset['Label']==1)]\n",
    "    rate=len(instance)/len(dataset)\n",
    "    return rate, len(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized_date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.972335</td>\n",
       "      <td>-0.392211</td>\n",
       "      <td>-1.281755</td>\n",
       "      <td>-0.652866</td>\n",
       "      <td>0.678335</td>\n",
       "      <td>0.551029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.071506</td>\n",
       "      <td>1.753434</td>\n",
       "      <td>0.774128</td>\n",
       "      <td>-0.836737</td>\n",
       "      <td>1.040375</td>\n",
       "      <td>1.151896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.175936</td>\n",
       "      <td>1.035057</td>\n",
       "      <td>0.746482</td>\n",
       "      <td>-0.832563</td>\n",
       "      <td>0.897440</td>\n",
       "      <td>1.160940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.154624</td>\n",
       "      <td>1.295163</td>\n",
       "      <td>0.776619</td>\n",
       "      <td>-0.859222</td>\n",
       "      <td>0.849481</td>\n",
       "      <td>1.193639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.218561</td>\n",
       "      <td>0.949184</td>\n",
       "      <td>0.823358</td>\n",
       "      <td>-0.891487</td>\n",
       "      <td>0.956682</td>\n",
       "      <td>1.092760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized_date  Latitude  Longitude  Pressure  Salinity  Temperature  \\\n",
       "0        -0.972335 -0.392211  -1.281755 -0.652866  0.678335     0.551029   \n",
       "1         1.071506  1.753434   0.774128 -0.836737  1.040375     1.151896   \n",
       "2         1.175936  1.035057   0.746482 -0.832563  0.897440     1.160940   \n",
       "3         1.154624  1.295163   0.776619 -0.859222  0.849481     1.193639   \n",
       "4         1.218561  0.949184   0.823358 -0.891487  0.956682     1.092760   \n",
       "\n",
       "   Label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(TRAIN_FILE)\n",
    "test_data = pd.read_csv(TEST_FILE)\n",
    "train_data.drop(['ID', 'Date'], axis=1, inplace=True)\n",
    "test_data.drop(['ID', 'Date'], axis=1, inplace=True)\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized_date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355416</td>\n",
       "      <td>0.579524</td>\n",
       "      <td>0.322254</td>\n",
       "      <td>-0.885756</td>\n",
       "      <td>1.002760</td>\n",
       "      <td>1.235034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.576606</td>\n",
       "      <td>1.294321</td>\n",
       "      <td>1.093063</td>\n",
       "      <td>-0.898463</td>\n",
       "      <td>0.996178</td>\n",
       "      <td>0.982373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.753954</td>\n",
       "      <td>0.365366</td>\n",
       "      <td>1.044996</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>-1.132805</td>\n",
       "      <td>-1.136430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964945</td>\n",
       "      <td>0.878866</td>\n",
       "      <td>0.942539</td>\n",
       "      <td>-0.820480</td>\n",
       "      <td>0.947279</td>\n",
       "      <td>0.915585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.261185</td>\n",
       "      <td>1.504443</td>\n",
       "      <td>0.953027</td>\n",
       "      <td>1.779428</td>\n",
       "      <td>-1.127163</td>\n",
       "      <td>-1.303981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58523</th>\n",
       "      <td>-0.531172</td>\n",
       "      <td>-0.468230</td>\n",
       "      <td>-0.065854</td>\n",
       "      <td>-0.882455</td>\n",
       "      <td>1.104320</td>\n",
       "      <td>1.255210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58524</th>\n",
       "      <td>-0.445923</td>\n",
       "      <td>-0.274119</td>\n",
       "      <td>-0.294182</td>\n",
       "      <td>1.667250</td>\n",
       "      <td>-1.138448</td>\n",
       "      <td>-1.300966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58525</th>\n",
       "      <td>0.502470</td>\n",
       "      <td>-0.138289</td>\n",
       "      <td>1.016256</td>\n",
       "      <td>-0.789773</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.778181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58526</th>\n",
       "      <td>-1.289887</td>\n",
       "      <td>-1.175349</td>\n",
       "      <td>-1.067926</td>\n",
       "      <td>-0.829574</td>\n",
       "      <td>1.049778</td>\n",
       "      <td>1.213235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58527</th>\n",
       "      <td>0.417222</td>\n",
       "      <td>0.270964</td>\n",
       "      <td>0.215042</td>\n",
       "      <td>-0.828390</td>\n",
       "      <td>1.175787</td>\n",
       "      <td>1.179841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58528 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Normalized_date  Latitude  Longitude  Pressure  Salinity  Temperature  \\\n",
       "0             0.355416  0.579524   0.322254 -0.885756  1.002760     1.235034   \n",
       "1             1.576606  1.294321   1.093063 -0.898463  0.996178     0.982373   \n",
       "2             0.753954  0.365366   1.044996  0.926038 -1.132805    -1.136430   \n",
       "3             0.964945  0.878866   0.942539 -0.820480  0.947279     0.915585   \n",
       "4             1.261185  1.504443   0.953027  1.779428 -1.127163    -1.303981   \n",
       "...                ...       ...        ...       ...       ...          ...   \n",
       "58523        -0.531172 -0.468230  -0.065854 -0.882455  1.104320     1.255210   \n",
       "58524        -0.445923 -0.274119  -0.294182  1.667250 -1.138448    -1.300966   \n",
       "58525         0.502470 -0.138289   1.016256 -0.789773  0.691500     0.778181   \n",
       "58526        -1.289887 -1.175349  -1.067926 -0.829574  1.049778     1.213235   \n",
       "58527         0.417222  0.270964   0.215042 -0.828390  1.175787     1.179841   \n",
       "\n",
       "       Label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "58523      0  \n",
       "58524      0  \n",
       "58525      0  \n",
       "58526      0  \n",
       "58527      0  \n",
       "\n",
       "[58528 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 4903218 ------\n",
      "Train: 175583; 0.84%\n",
      "Test: 58528; 0.84%\n"
     ]
    }
   ],
   "source": [
    "print(f'------- {float_number} ------')\n",
    "print(f'Train: {train_data.shape[0]}; {round(comp_ratio(train_data)[0]*100, 2)}%')\n",
    "print(f'Test: {test_data.shape[0]}; {round(comp_ratio(test_data)[0]*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(train_data, test_data, label_column, sampling_ratio):\n",
    "    # Separate features and labels\n",
    "    train_labels = train_data[label_column]\n",
    "    train_features = train_data.drop(label_column, axis=1)\n",
    "    test_labels = test_data[label_column]\n",
    "    test_features = test_data.drop(label_column, axis=1)\n",
    "\n",
    "    # Randomly select a subset of the train set\n",
    "    train_features_sample, _, train_labels_sample, _ = train_test_split(train_features, train_labels, train_size=sampling_ratio, random_state=42)\n",
    "\n",
    "    return train_features_sample, train_labels_sample, test_features, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized_date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130108</th>\n",
       "      <td>-0.488548</td>\n",
       "      <td>-0.277046</td>\n",
       "      <td>-0.178464</td>\n",
       "      <td>-0.903508</td>\n",
       "      <td>1.191773</td>\n",
       "      <td>1.293822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50340</th>\n",
       "      <td>-0.761344</td>\n",
       "      <td>-0.844432</td>\n",
       "      <td>-0.742107</td>\n",
       "      <td>-0.799676</td>\n",
       "      <td>1.010283</td>\n",
       "      <td>0.949907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15829</th>\n",
       "      <td>-1.225950</td>\n",
       "      <td>-1.428635</td>\n",
       "      <td>-1.178019</td>\n",
       "      <td>1.271792</td>\n",
       "      <td>-1.137507</td>\n",
       "      <td>-1.227684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154238</th>\n",
       "      <td>-0.951023</td>\n",
       "      <td>-0.369676</td>\n",
       "      <td>-1.257610</td>\n",
       "      <td>-0.826086</td>\n",
       "      <td>1.092095</td>\n",
       "      <td>0.873958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18460</th>\n",
       "      <td>-1.247262</td>\n",
       "      <td>-1.366578</td>\n",
       "      <td>-1.105354</td>\n",
       "      <td>0.648863</td>\n",
       "      <td>-1.220259</td>\n",
       "      <td>-1.103499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Normalized_date  Latitude  Longitude  Pressure  Salinity  Temperature\n",
       "130108        -0.488548 -0.277046  -0.178464 -0.903508  1.191773     1.293822\n",
       "50340         -0.761344 -0.844432  -0.742107 -0.799676  1.010283     0.949907\n",
       "15829         -1.225950 -1.428635  -1.178019  1.271792 -1.137507    -1.227684\n",
       "154238        -0.951023 -0.369676  -1.257610 -0.826086  1.092095     0.873958\n",
       "18460         -1.247262 -1.366578  -1.105354  0.648863 -1.220259    -1.103499"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage \n",
    "label_column = 'Label'  # Name of the label column in the CSV files\n",
    "sampling_ratio = 0.99 # Sampling ratio of 0.5 (50%)\n",
    "\n",
    "# Perform random sampling\n",
    "train_features_sample, train_labels_sample, test_features, test_labels = random_sampling(train_data, test_data, label_column, sampling_ratio)\n",
    "train_features_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008372108917150293"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contamination = comp_ratio(train_data)[0]\n",
    "contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling Ratio</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Cohen's Kappa</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOF</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>0.028602</td>\n",
       "      <td>[[57566, 472], [472, 18]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iForest</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008443</td>\n",
       "      <td>[[57548, 490], [490, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.032653</td>\n",
       "      <td>0.056437</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>[[57977, 61], [474, 16]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Sampling Ratio  Precision    Recall  F1-score  Cohen's Kappa  \\\n",
       "0      LOF            0.99   0.036735  0.036735  0.036735       0.028602   \n",
       "1  iForest            0.99   0.000000  0.000000  0.000000      -0.008443   \n",
       "2   DBSCAN            0.99   0.207792  0.032653  0.056437       0.054287   \n",
       "\n",
       "            Confusion Matrix  \n",
       "0  [[57566, 472], [472, 18]]  \n",
       "1   [[57548, 490], [490, 0]]  \n",
       "2   [[57977, 61], [474, 16]]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_predict_model(model_name, test_features):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(test_features)\n",
    "        \n",
    "    if model_name == 'LOF':\n",
    "        model = LocalOutlierFactor(n_neighbors = 20, contamination=contamination)\n",
    "        labels_lof = model.fit_predict(X_scaled)\n",
    "        predictions = np.where(labels_lof == -1, 1, 0)\n",
    "\n",
    "    elif model_name == 'iForest':\n",
    "        model = IsolationForest(n_estimators=20, random_state=42, contamination=contamination)\n",
    "        model.fit(X_scaled)\n",
    "        predictions = np.where(model.predict(X_scaled) == -1, 1, 0)\n",
    "\n",
    "    elif model_name == 'OCSVM':\n",
    "        X_norm = train_features[train_labels==0]\n",
    "        # Standardize the features\n",
    "        scaler = StandardScaler()\n",
    "        X_norm_scaled = scaler.fit_transform(X_norm)\n",
    "\n",
    "        # Fit the OC-SVM model\n",
    "        model = OneClassSVM(nu=0.01, kernel='rbf', gamma='scale')  # You can adjust parameters as needed\n",
    "        model.fit(X_norm_scaled)\n",
    "    \n",
    "    elif model_name == 'DBSCAN': \n",
    "        # Create a DBSCAN model\n",
    "        eps = 0.3  # The maximum distance between two samples for one to be considered as in the neighborhood of the other\n",
    "        min_samples = 20  # The number of samples (or total weight) in a neighborhood for a point to be considered as a core point\n",
    "        model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels_dbscan = model.fit_predict(X_scaled)\n",
    "        predictions = np.where(labels_dbscan == -1, 1, 0)\n",
    "\n",
    "        # # Strategy 1: Map two clusters (0 and 1) to binary classes directly\n",
    "        # # This is straightforward if DBSCAN found exactly 2 clusters\n",
    "        # if len(np.unique(labels_dbscan)) == 3:  # Two clusters + noise\n",
    "        #     binary_labels = np.where(labels_dbscan == -1, 2, labels_dbscan)  # Temporarily map noise to 2\n",
    "        #     unique_clusters = np.unique(binary_labels)\n",
    "        #     mapping = {unique_clusters[0]: 0, unique_clusters[1]: 1, 2: 0}  # Example mapping, noise to 0\n",
    "        #     predictions = np.vectorize(mapping.get)(binary_labels)\n",
    "\n",
    "        # # Strategy 2: One cluster and noise\n",
    "        # # Here, we treat the cluster as 1 and noise as 0\n",
    "        # elif len(np.unique(labels_dbscan)) == 2 and -1 in labels_dbscan:\n",
    "        #     predictions = np.where(labels_dbscan == -1, 0, 1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model name: {model_name}\")\n",
    "    return predictions\n",
    "\n",
    "def evaluate_model(predictions, test_labels):\n",
    "    precision = precision_score(test_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(test_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(test_labels, predictions, zero_division=0)\n",
    "    kappa = cohen_kappa_score(test_labels, predictions)\n",
    "    confusion = confusion_matrix(test_labels, predictions)\n",
    "    return precision, recall, f1, kappa, confusion\n",
    "\n",
    "# Usage \n",
    "sampling_ratio = 0.99 # Sampling ratio of 0.5 (50%)\n",
    "\n",
    "# Perform random sampling\n",
    "train_features_sample, train_labels_sample, test_features, test_labels = random_sampling(train_data, test_data, label_column, sampling_ratio)\n",
    "\n",
    "\n",
    "model_names = ['LOF', 'iForest', 'DBSCAN']  # Model names to evaluate\n",
    "# model_names = ['LOF']  # Model names to evaluate\n",
    "results = []\n",
    "for model_name in model_names: \n",
    "    # Fit a model on the sampled train set\n",
    "    predictions = fit_predict_model(model_name, test_features)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    precision, recall, f1, kappa, confusion = evaluate_model(predictions, test_labels)\n",
    "    result = {'Model': model_name, 'Sampling Ratio': sampling_ratio,\n",
    "                                            'Precision': precision, 'Recall': recall, 'F1-score': f1, \"Cohen's Kappa\": kappa, 'Confusion Matrix': confusion}\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float: 4903218\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "  Model &  Precision &  Recall &  F1-score &  Cohen's Kappa \\\\\n",
      "\\midrule\n",
      "    LOF &     0.0367 &  0.0367 &    0.0367 &         0.0286 \\\\\n",
      "iForest &     0.0000 &  0.0000 &    0.0000 &        -0.0084 \\\\\n",
      " DBSCAN &     0.2078 &  0.0327 &    0.0564 &         0.0543 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2278824/3516080423.py:11: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = filtered_results.to_latex(index=False, escape=False)\n"
     ]
    }
   ],
   "source": [
    "filtered_results = results_df[results_df['Sampling Ratio'] == 0.99]\n",
    "\n",
    "# Select the desired columns\n",
    "selected_columns = ['Model', 'Precision', 'Recall', 'F1-score', \"Cohen's Kappa\"]\n",
    "filtered_results = filtered_results[selected_columns]\n",
    "\n",
    "# Round numerical values to 4 decimals\n",
    "filtered_results = filtered_results.round(4)\n",
    "\n",
    "# Convert the results to LaTeX table format\n",
    "latex_table = filtered_results.to_latex(index=False, escape=False)\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(f\"Float: {float_number}\")\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../results/randomsplit/4903054/unsupervised_random_sampling.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the results to a CSV file\n",
    "output_file = os.path.join(RESULT_DIR, 'unsupervised_random_sampling.csv')\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(\"Results saved to:\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-quality-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
