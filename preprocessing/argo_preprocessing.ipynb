{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "This notebook preprocesses data downloaded from the Argo data platform to experimental data. The preprocessing precedure follows the following steps: \n",
    "- Select relevant columns and drop NAN rows\n",
    "- Add global QC labels to each row\n",
    "- Rename columns\n",
    "- Normalize data (z-score standardization)\n",
    "\n",
    "See Argo QC flag scale @ ./argo_qc_flag_scale.png\n",
    "\n",
    "\n",
    "Input: \n",
    "- `../data/original_data/Atlantic_2019_03`\n",
    "\n",
    "Output: \n",
    "- `../data/preprocessed_data/Atlantic_2019_03`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = '../data/original_data/Atlantic_2019_03'\n",
    "PREPROCESSED_DATA_DIR = '../data/preprocessed_data/Atlantic_2019_03'\n",
    "NORMALIZED_DATA_DIR = '../data/preprocessed_data/Atlantic_2019_03/normalized'\n",
    "\n",
    "os.makedirs(PREPROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(NORMALIZED_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute data error rate\n",
    "def comp_error_ratio(dataset):\n",
    "    instance = dataset[(dataset['Label']==1)]\n",
    "    rate=len(instance)/len(dataset)*100\n",
    "    return round(rate,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add global QC label to each record. \n",
    "# If all QC are `1`, assign the label `0`(normal). Otherwise assign the label `1`(abnormal). \n",
    "def add_global_qc_label(df):\n",
    "    values = df[['DATE_QC', 'POSITION_QC', 'PRES_QC', 'PSAL_QC', 'TEMP_QC']]\n",
    "    is_all_normal = values.isin({1}).all(axis=1)\n",
    "    label_values = is_all_normal.map(lambda x: 0 if x else 1)\n",
    "    df['Label'] = label_values \n",
    "\n",
    "    print(f'Error rate: {comp_error_ratio(df)}%')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d34aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names\n",
    "column_map = {\n",
    "              # 'PLATFORM_CODE': 'Platform_code', \n",
    "              'ID': 'ID', \n",
    "              'DATE (YYYY-MM-DDTHH:MI:SSZ)': 'Datetime',\n",
    "              'LATITUDE (degree_north)': 'Latitude', \n",
    "              'LONGITUDE (degree_east)': 'Longitude', \n",
    "              'PRES (decibar)': 'Pressure', \n",
    "              'PSAL (psu)': 'Salinity', \n",
    "              'TEMP (degree_Celsius)': 'Temperature', \n",
    "              'Label': 'Label', \n",
    "              # 'PRES_ADJUSTED (decibar)': 'pressure_adjusted', \n",
    "              # '': '', \n",
    "             }\n",
    "def change_column_names(df): \n",
    "    df.rename(columns=column_map, inplace=True)\n",
    "    data = df[list(column_map.values())]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def standardize_columns(df, columns):\n",
    "    df_standardized = df.copy()\n",
    "    for column in columns:\n",
    "        col_mean = df[column].mean()\n",
    "        col_std = df[column].std()\n",
    "        df_standardized[column] = (df[column] - col_mean) / col_std\n",
    "    return df_standardized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize date\n",
    "def normalize_date_column(df, date_column, reference_date=None):\n",
    "    df_normalized = df.copy()\n",
    "    df_normalized[date_column] = pd.to_datetime(df_normalized[date_column])\n",
    "    \n",
    "    if reference_date is None:\n",
    "        reference_date = df_normalized[date_column].min()\n",
    "\n",
    "    df_normalized['DaysSinceReference'] = (df_normalized[date_column] - reference_date).dt.days\n",
    "    \n",
    "    col_mean = df_normalized['DaysSinceReference'].mean()\n",
    "    col_std = df_normalized['DaysSinceReference'].std()\n",
    "    \n",
    "    df_normalized.insert(2, 'Normalized_date', (df_normalized['DaysSinceReference'] - col_mean) / col_std)\n",
    "    # df_normalized['Normalized_date'] = (df_normalized['DaysSinceReference'] - col_mean) / col_std\n",
    "    \n",
    "    return df_normalized.drop(columns=['DaysSinceReference'])\n",
    "\n",
    "# Sample DataFrame with a date column\n",
    "data = {'Date': ['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01', '2022-05-01'],\n",
    "        'Value': [10, 20, 30, 40, 50]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize the 'Date' column using a reference date of '2010-01-01'\n",
    "normalized_df = normalize_date_column(df, date_column='Date', reference_date=pd.Timestamp('2010-03-20'))\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nNormalized DataFrame:\")\n",
    "print(normalized_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a39430",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = ORIGINAL_DATA_DIR\n",
    "output_dir = PREPROCESSED_DATA_DIR\n",
    "normalized_dir = NORMALIZED_DATA_DIR\n",
    "file_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "\n",
    "print(f'Input dir: {input_dir}')\n",
    "print(f'Output dir: {output_dir}')\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        normalized_path = os.path.join(normalized_dir, filename)\n",
    "\n",
    "        df = pd.read_csv(input_path)\n",
    "        print(f'-------- {filename} --------')\n",
    "\n",
    "        # Select relevant columns\n",
    "        df = df[['DATE (YYYY-MM-DDTHH:MI:SSZ)', 'DATE_QC',\n",
    "       'LATITUDE (degree_north)', 'LONGITUDE (degree_east)', 'POSITION_QC',\n",
    "       'PRES (decibar)', 'PRES_QC', 'PSAL (psu)', 'PSAL_QC',\n",
    "       'TEMP (degree_Celsius)', 'TEMP_QC']]\n",
    "        \n",
    "        # Drop NAN rows\n",
    "        df= df.dropna()\n",
    "\n",
    "        # Add ID to each sample\n",
    "        df.insert(0, 'ID', range(1, len(df)+1))\n",
    "\n",
    "        # Add global QC labels\n",
    "        df = add_global_qc_label(df)\n",
    "        \n",
    "        # Change column names\n",
    "        df = change_column_names(df)\n",
    "\n",
    "        # Save the preprocessed data\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        # Normalize the data\n",
    "        df = standardize_columns(df, ['Latitude','Longitude','Pressure','Salinity','Temperature'])\n",
    "\n",
    "        # Normalize the date\n",
    "        df.insert(1, 'Date', pd.to_datetime(df['Datetime']).dt.date)\n",
    "        df.drop('Datetime', axis=1, inplace=True)\n",
    "        df = normalize_date_column(df, date_column='Date', reference_date=pd.Timestamp('2015-01-01'))\n",
    "        \n",
    "        # Save the normalized data\n",
    "        df.to_csv(normalized_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc92b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-quality-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
